{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samgab02/AI_Course_Road2/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oys2va8xvWps",
        "outputId": "3685459e-0793-427f-90d0-d5ac416241d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 7443.8623\n",
            "Epoch 2/500\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 767.5987\n",
            "Epoch 3/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 553.8256\n",
            "Epoch 4/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 352.7200\n",
            "Epoch 5/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 196.7727\n",
            "Epoch 6/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 90.9466\n",
            "Epoch 7/500\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 33.4024\n",
            "Epoch 8/500\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 8.1094\n",
            "Epoch 9/500\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.1232\n",
            "Epoch 10/500\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0660\n",
            "Epoch 11/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0010\n",
            "Epoch 12/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 2.1630e-06\n",
            "Epoch 13/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.4157e-08\n",
            "Epoch 14/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 5.2738e-09\n",
            "Epoch 15/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.8883e-09\n",
            "Epoch 16/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 9.4887e-10\n",
            "Epoch 17/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.1342e-09\n",
            "Epoch 18/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.0047e-06\n",
            "Epoch 19/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0266\n",
            "Epoch 20/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2081\n",
            "Epoch 21/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 3.3172e-07\n",
            "Epoch 22/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.4099e-09\n",
            "Epoch 23/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5760e-08\n",
            "Epoch 24/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.1044\n",
            "Epoch 25/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.0380e-04\n",
            "Epoch 26/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 3.1974e-09\n",
            "Epoch 27/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 4.8825e-07\n",
            "Epoch 28/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1430\n",
            "Epoch 29/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 3.4780e-10\n",
            "Epoch 30/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.5686e-06\n",
            "Epoch 31/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0400\n",
            "Epoch 32/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 4.9861e-07\n",
            "Epoch 33/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0747\n",
            "Epoch 34/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 5.0770e-07\n",
            "Epoch 35/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 8.7442e-08\n",
            "Epoch 36/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.0270\n",
            "Epoch 37/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.4144e-04\n",
            "Epoch 38/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0452\n",
            "Epoch 39/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 7.1882e-07\n",
            "Epoch 40/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1921\n",
            "Epoch 41/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 3.5628e-07\n",
            "Epoch 42/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 2.5677e-09\n",
            "Epoch 43/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 5.6790e-09\n",
            "Epoch 44/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0728\n",
            "Epoch 45/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 3.7206e-08\n",
            "Epoch 46/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 4.6943e-07\n",
            "Epoch 47/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.0310\n",
            "Epoch 48/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 8.9705e-08\n",
            "Epoch 49/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0870\n",
            "Epoch 50/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 2.2759e-10\n",
            "Epoch 51/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 2.1678e-06\n",
            "Epoch 52/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0315\n",
            "Epoch 53/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 2.3190e-06\n",
            "Epoch 54/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.2613\n",
            "Epoch 55/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 6.5783e-10\n",
            "Epoch 56/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.7676e-10\n",
            "Epoch 57/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 2.7464e-08\n",
            "Epoch 58/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.0523\n",
            "Epoch 59/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 8.2632e-05\n",
            "Epoch 60/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 6.1548e-05\n",
            "Epoch 61/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0668\n",
            "Epoch 62/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 3.5538e-08\n",
            "Epoch 63/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 4.7190e-04\n",
            "Epoch 64/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0579\n",
            "Epoch 65/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 9.3932e-08\n",
            "Epoch 66/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0484\n",
            "Epoch 67/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.1655e-04\n",
            "Epoch 68/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.8162e-04\n",
            "Epoch 69/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.0842\n",
            "Epoch 70/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 5.3820e-09\n",
            "Epoch 71/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.2466e-08\n",
            "Epoch 72/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0382\n",
            "Epoch 73/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.8290e-07\n",
            "Epoch 74/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0419\n",
            "Epoch 75/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.1913e-05\n",
            "Epoch 76/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0043\n",
            "Epoch 77/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0385\n",
            "Epoch 78/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0018\n",
            "Epoch 79/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0706\n",
            "Epoch 80/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 2.9856e-08\n",
            "Epoch 81/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.0424\n",
            "Epoch 82/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 3.4408e-06\n",
            "Epoch 83/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 1.7413e-04\n",
            "Epoch 84/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4662\n",
            "Epoch 85/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 2.1299e-09\n",
            "Epoch 86/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 2.2668e-09\n",
            "Epoch 87/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 4.7968e-10\n",
            "Epoch 88/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0100\n",
            "Epoch 89/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.0124\n",
            "Epoch 90/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0189\n",
            "Epoch 91/500\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0317\n",
            "Epoch 92/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 3.4792e-04\n",
            "Epoch 93/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.0855\n",
            "Epoch 94/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 3.8312e-04\n",
            "Epoch 95/500\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 7.0029e-09\n",
            "Epoch 96/500\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 2.3044e-05\n",
            "Epoch 97/500\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.0611\n",
            "Epoch 98/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 9.5184e-06\n",
            "Epoch 99/500\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.0031\n",
            "Epoch 100/500\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.1934\n",
            "Epoch 101/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.3705e-09\n",
            "Epoch 102/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 8.2355e-10\n",
            "Epoch 103/500\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0815\n",
            "Epoch 104/500\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0058\n",
            "Epoch 105/500\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.9768e-09\n",
            "Epoch 106/500\n",
            "568/800 [====================>.........] - ETA: 0s - loss: 1.6614e-08"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Function to convert Celsius to Fahrenheit using the trained model\n",
        "def celsius_to_fahrenheit(celsius_value):\n",
        "    return model.predict([celsius_value])[0][0]\n",
        "\n",
        "# Generate some data for training\n",
        "celsius = np.random.uniform(low=-100, high=100, size=1000)\n",
        "fahrenheit = (celsius * 1.8) + 32\n",
        "\n",
        "# Create a DataFrame with Celsius and Fahrenheit columns\n",
        "data = {'Celsius': celsius, 'Fahrenheit': fahrenheit}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('celsius_to_fahrenheit_dataset.csv', index=False)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('celsius_to_fahrenheit_dataset.csv')\n",
        "\n",
        "# Build a simple neural network with a specified learning rate\n",
        "custom_optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "# Compile the model with custom optimizer and mean squared error loss\n",
        "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "celsius_train, celsius_test, fahrenheit_train, fahrenheit_test = train_test_split(df['Celsius'], df['Fahrenheit'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model with 500 epochs and batch size 1\n",
        "history = model.fit(celsius_train, fahrenheit_train, epochs=500, batch_size=1, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss = model.evaluate(celsius_test, fahrenheit_test)\n",
        "print(f'Mean Squared Error on Test Set: {loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model with a sample input\n",
        "sample_celsius = 0\n",
        "predicted_fahrenheit = celsius_to_fahrenheit(sample_celsius)\n",
        "print(f'{sample_celsius} Celsius is approximately {predicted_fahrenheit} Fahrenheit')\n",
        "\n",
        "# Choose a Celsius value not in the dataset\n",
        "new_celsius = 25\n",
        "\n",
        "# Use the real conversion formula to calculate the true Fahrenheit value\n",
        "true_fahrenheit = (new_celsius * 1.8) + 32\n",
        "\n",
        "# Use the trained model to predict the Fahrenheit value\n",
        "predicted_fahrenheit = celsius_to_fahrenheit(new_celsius)\n",
        "\n",
        "# Calculate the absolute error\n",
        "error = abs(true_fahrenheit - predicted_fahrenheit)\n",
        "\n",
        "# Print the results\n",
        "print(f'\\nCelsius: {new_celsius} (True Fahrenheit: {true_fahrenheit:.2f}, Predicted Fahrenheit: {predicted_fahrenheit:.2f})')\n",
        "print(f'Absolute Error: {error:.2f} Fahrenheit')\n",
        "\n",
        "# Plot the training loss over epochs\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wILaPi3WCvPC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdIbEUQ3gSsKppYj4CtxAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}